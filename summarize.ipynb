{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ce6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgitb import text\n",
    "# from traceback import print_tb\n",
    "# from transformers import pipeline\n",
    "# from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# print('Please Enter the link to the YouTube Video')\n",
    "# link = input()\n",
    "# video_id = link.split(\"=\")[1]\n",
    "# transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "# full_transcript = \"\"\n",
    "# for x in transcript:\n",
    "#     full_transcript += \" \" + x['text']\n",
    "\n",
    "# print(len(full_transcript))\n",
    "\n",
    "# summerizar = pipeline(\"summarization\")\n",
    "\n",
    "# itr = int(len(full_transcript)/400)\n",
    "# summary_text = []\n",
    "# for i in range(0, itr+1):\n",
    "#     start = 0\n",
    "#     start = i*400\n",
    "    \n",
    "#     end = (i+1)*400\n",
    "#     out = summerizar(full_transcript[start:end], max_length=57)\n",
    "#     out = out[0]\n",
    "#     out = out[\"summary_text\"]\n",
    "#     summary_text.append(out)\n",
    "\n",
    "# print(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84ce8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your max_length is set to 57, but you input_length is only 28. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 200 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['डैगन स्क्रॉल की शक्ति है.. मेरा! यह कुछ नहीं है! मुझे इसे पहली बार भी नहीं मिला था. वहाँ कोई गुप्त घटक नहीं है. यह सिर्फ आप हैं. मैं चीखने जा रहा हूँ! मत करें! मत करें! आप सिर्फ']\n"
     ]
    }
   ],
   "source": [
    "from cgitb import text\n",
    "from traceback import print_tb\n",
    "from transformers import pipeline\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from curses.textpad import Textbox\n",
    "import string\n",
    "from time import strftime, time\n",
    "from tkinter import*\n",
    "import tkinter as tk\n",
    "from tkinter.ttk import Progressbar\n",
    "from PIL import Image,ImageTk,ImageDraw\n",
    "from tkinter import messagebox\n",
    "from datetime import datetime\n",
    "from time import strftime\n",
    "from pytz import timezone\n",
    "import time\n",
    "root=tk.Tk()\n",
    "root.grid_rowconfigure(0, weight=1)\n",
    "root.grid_columnconfigure(0, weight=1)\n",
    "root.geometry(\"1550x800+0+0\")\n",
    "root['bg']='black'\n",
    "root.title(\"Youtube-Transcript Summarizer\")\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n",
    "#========================================= time ==========================================================#\n",
    "def current_time():\n",
    "    now_utc = datetime.now(timezone('UTC'))\n",
    "    now_asia = now_utc.astimezone(timezone('Asia/Kolkata'))\n",
    "    string=now_asia.strftime('%H:%M:%S %p')\n",
    "    lbl.config(text=string)\n",
    "    lbl.after(1000,current_time)\n",
    "\n",
    "lbl=Label(root,font=(SUNKEN,15,'bold'),fg='white',bg='black',border=0,borderwidth=0)\n",
    "lbl.place(x=1,y=5)\n",
    "current_time()\n",
    "        \n",
    "#======================================= Heading ========================================================#\n",
    "img1=Image.open(r\"image_resource\\you_img.jpg\")\n",
    "img1=img1.resize((130,120),Image.ANTIALIAS)\n",
    "img1=ImageTk.PhotoImage(img1)\n",
    "\n",
    "hd_img1=Label(root,image=img1,bg='black')\n",
    "hd_img1.place(x=1040,y=3.5)\n",
    "hd_text=Label(root,text=\"Youtube Transcript Summarizer\",font=(SUNKEN,30,'bold'),fg='white',bg='black',border=0,borderwidth=0)\n",
    "hd_text.place(x=450,y=30)\n",
    "\n",
    "#======================================== Exit Button ===================================================#\n",
    "def exit_fun():\n",
    "    root.destroy()\n",
    "def iExit():\n",
    "    iExit_t=messagebox.askyesno(\"Exit\",\"Do you want to exit\")\n",
    "    if iExit_t>0:\n",
    "        root.destroy()\n",
    "    else:\n",
    "        return    \n",
    "exit_btn=Button(root,text='Quit',bg='red',command=iExit,font=('Arial',13,'bold'),fg='white',activebackground='red',activeforeground='white',border=0,borderwidth=3,cursor='hand2',relief=RIDGE)\n",
    "exit_btn.place(x=1400,y=10,width=100,height=25)\n",
    "\n",
    "\n",
    "#====================================== get-started & stop ==============================================#\n",
    "def getlink():\n",
    "    link=StringVar()\n",
    "    \n",
    "    def var_text():\n",
    "        name=link.get()\n",
    "        with open(\"link.txt\", \"w\") as text_file:\n",
    "            text_file.write(name)\n",
    "        link.set(\"\")\n",
    "        \n",
    "        progress = Progressbar(root, orient = HORIZONTAL,length = 200, mode = 'determinate')\n",
    "        def youtube():\n",
    "            progress['value'] = 40\n",
    "            root.update_idletasks()\n",
    "            time.sleep(0.5)\n",
    "            myfile = open('link.txt', \"r\")\n",
    "            you_link = myfile.readline()\n",
    "            myfile.close()\n",
    "            video_id = you_link.split(\"=\")[1]\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            full_transcript = \"\"\n",
    "            for x in transcript:\n",
    "                full_transcript += \" \" + x['text']\n",
    "\n",
    "            print(len(full_transcript))\n",
    "            \n",
    "            progress['value'] = 80\n",
    "            root.update_idletasks()\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            summerizar = pipeline(\"summarization\")\n",
    "            itr = int(len(full_transcript)/400)\n",
    "            summary_text = []\n",
    "            \n",
    "            progress['value'] = 120\n",
    "            root.update_idletasks()\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            for i in range(0, itr+1):\n",
    "                start = 0\n",
    "                start = i*400\n",
    "    \n",
    "                end = (i+1)*400\n",
    "                out = summerizar(full_transcript[start:end], max_length=57)\n",
    "                out = out[0]\n",
    "                out = out[\"summary_text\"]\n",
    "                summary_text.append(out)\n",
    "                \n",
    "            progress['value'] = 160\n",
    "            root.update_idletasks()\n",
    "            time.sleep(0.1)    \n",
    "            \n",
    "            with open(\"summary.txt\", \"w\") as text_file:\n",
    "                text_file.write(summary_text[0])\n",
    "                \n",
    "            progress['value'] = 200\n",
    "            root.update_idletasks()\n",
    "            time.sleep(1) \n",
    "        progress.place(x=1150,y=245)    \n",
    "        transcribe=Button(root,text='Transcribe',bg='green',command=youtube,font=('Arial',13,'bold'),fg='white',activebackground='red',activeforeground='white',border=0,borderwidth=3,cursor='hand2',relief=RIDGE)\n",
    "        transcribe.place(x=1000,y=240,width=137,height=32)\n",
    "\n",
    "    link_lbl=Label(root,text=\"Enter URL\",bg='black',fg='light blue',font=('SUNKEN',13,'bold'))\n",
    "    link_lbl.place(x=100,y=250)\n",
    "    link_data=tk.Entry(root,width=20,textvariable=link,font=('SUNKEN',13,'normal'))\n",
    "    link_data.place(x=200,y=250)\n",
    "    \n",
    "    sub_btn=Button(root,text=\"Submit\",command=var_text,bg='white',fg='black',border=1,borderwidth=3,font=('Arial',10),activebackground='green')\n",
    "    sub_btn.place(x=400,y=250,height=25)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "start_img=Image.open(r\"image_resource\\button_activate.png\")\n",
    "start_img=start_img.resize((204,55),Image.ANTIALIAS)\n",
    "start_img=ImageTk.PhotoImage(start_img)\n",
    "start=Button(root,command=getlink,image=start_img,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "start.place(x=670,y=160,width=207,height=57)\n",
    "\n",
    "stop_img=Image.open(r\"image_resource\\button_stop (3).png\")\n",
    "stop_img=stop_img.resize((140,34),Image.ANTIALIAS)\n",
    "stop_img=ImageTk.PhotoImage(stop_img)\n",
    "stop=Button(root,image=stop_img,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "stop.place(x=710,y=700,width=150,height=37)\n",
    "#========================================= text-area =====================================================#\n",
    "txtarea = Text(root,wrap=WORD,bg='lavender',font=(\"TimesNewRoman\",11),width=90, height=20,borderwidth=4,relief='solid',padx=10,pady=10,spacing2=5)\n",
    "txtarea.pack(pady=100)\n",
    "txtarea.place(x=400,y=320)\n",
    "#======================================= Get Link & API call ======================================================#\n",
    "\n",
    "def english():\n",
    "    txtarea.delete('1.0', END)\n",
    "    file = open('summary.txt', \"r\")\n",
    "    data = file.readline()\n",
    "    file.close()\n",
    "    txtarea.delete('1.0', END)\n",
    "    txtarea.insert(tk.END, data )\n",
    "    \n",
    "def hindi():\n",
    "    txtarea.delete('1.0', END)                                             \n",
    "    file = open('summary.txt',\"r\")\n",
    "    data = file.readline()\n",
    "    file.close()\n",
    "    model_inputs = tokenizer(data, return_tensors=\"pt\")\n",
    "    # translate from English to Hindi\n",
    "    generated_tokens = model.generate(\n",
    "        **model_inputs,\n",
    "         forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
    "    )\n",
    "    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    print(translation)\n",
    "    txtarea.insert(tk.END, translation )\n",
    "    \n",
    "def german():\n",
    "    txtarea.delete('1.0', END)                                             \n",
    "    file = open('summary.txt',\"r\")\n",
    "    data = file.readline()\n",
    "    file.close()\n",
    "    model_inputs = tokenizer(data, return_tensors=\"pt\")\n",
    "    # translate from English to Hindi\n",
    "    generated_tokens = model.generate(\n",
    "        **model_inputs,\n",
    "         forced_bos_token_id=tokenizer.lang_code_to_id[\"de_DE\"]\n",
    "    )\n",
    "    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    print(translation)\n",
    "    txtarea.insert(tk.END, translation )\n",
    "    \n",
    "# def french():\n",
    "#     txtarea.delete('1.0', END)                                             \n",
    "#     file = open('summary.txt',\"r\")\n",
    "#     data = file.readline()\n",
    "#     file.close()\n",
    "#     model_inputs = tokenizer(data, return_tensors=\"pt\")\n",
    "#     # translate from English to Hindi\n",
    "#     generated_tokens = model.generate(\n",
    "#         **model_inputs,\n",
    "#          forced_bos_token_id=tokenizer.lang_code_to_id[\"fr_XX\"]\n",
    "#     )\n",
    "#     translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "#     print(translation)\n",
    "#     txtarea.insert(tk.END, translation ) \n",
    "    \n",
    "# def bengali():\n",
    "#     txtarea.delete('1.0', END)                                             \n",
    "#     file = open('summary.txt',\"r\")\n",
    "#     data = file.readline()\n",
    "#     file.close()\n",
    "#     model_inputs = tokenizer(data, return_tensors=\"pt\")\n",
    "#     # translate from English to Hindi\n",
    "#     generated_tokens = model.generate(\n",
    "#         **model_inputs,\n",
    "#          forced_bos_token_id=tokenizer.lang_code_to_id[\"bn_IN\"]\n",
    "#     )\n",
    "#     translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "#     print(translation)\n",
    "#     txtarea.insert(tk.END, translation ) \n",
    "    \n",
    "# def chinese():\n",
    "#     txtarea.delete('1.0', END)                                             \n",
    "#     file = open('summary.txt',\"r\")\n",
    "#     data = file.readline()\n",
    "#     file.close()\n",
    "#     model_inputs = tokenizer(data, return_tensors=\"pt\")\n",
    "#     # translate from English to Hindi\n",
    "#     generated_tokens = model.generate(\n",
    "#         **model_inputs,\n",
    "#          forced_bos_token_id=tokenizer.lang_code_to_id[\"zh_CN\"]\n",
    "#     )\n",
    "#     translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "#     print(translation)\n",
    "#     txtarea.insert(tk.END, translation ) \n",
    "    \n",
    "# def tamil():\n",
    "#     txtarea.delete('1.0', END)                                             \n",
    "#     file = open('summary.txt',\"r\")\n",
    "#     data = file.readline()\n",
    "#     file.close()\n",
    "#     model_inputs = tokenizer(data, return_tensors=\"pt\")\n",
    "#     # translate from English to Hindi\n",
    "#     generated_tokens = model.generate(\n",
    "#         **model_inputs,\n",
    "#          forced_bos_token_id=tokenizer.lang_code_to_id[\"ta_IN\"]\n",
    "#     )\n",
    "#     translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "#     print(translation)\n",
    "#     txtarea.insert(tk.END, translation ) \n",
    "    \n",
    "# def telugu():\n",
    "#     txtarea.delete('1.0', END)                                             \n",
    "#     file = open('summary.txt',\"r\")\n",
    "#     data = file.readline()\n",
    "#     file.close()\n",
    "#     model_inputs = tokenizer(data, return_tensors=\"pt\")\n",
    "#     # translate from English to Hindi\n",
    "#     generated_tokens = model.generate(\n",
    "#         **model_inputs,\n",
    "#          forced_bos_token_id=tokenizer.lang_code_to_id[\"te_IN\"]\n",
    "#     )\n",
    "#     translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "#     print(translation)\n",
    "#     txtarea.insert(tk.END, translation )    \n",
    "#======================================= Language-button ===============================================#\n",
    "\n",
    "\n",
    "btn_eng=Image.open(r\"image_resource\\button_english.png\")\n",
    "btn_eng=btn_eng.resize((132,34),Image.ANTIALIAS)\n",
    "btn_eng=ImageTk.PhotoImage(btn_eng)\n",
    "eng=Button(root,image=btn_eng,command=english,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "eng.place(x=200,y=340,width=135,height=37)\n",
    "\n",
    "btn_hindi=Image.open(r\"image_resource\\button_hindi.png\")\n",
    "btn_hindi=btn_hindi.resize((132,34),Image.ANTIALIAS)\n",
    "btn_hindi=ImageTk.PhotoImage(btn_hindi)\n",
    "hindi=Button(root,image=btn_hindi,command=hindi,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "hindi.place(x=200,y=440,width=135,height=37)\n",
    "\n",
    "btn_german=Image.open(r\"image_resource\\button_german.png\")\n",
    "btn_german=btn_german.resize((132,34),Image.ANTIALIAS)\n",
    "btn_german=ImageTk.PhotoImage(btn_german)\n",
    "german=Button(root,image=btn_german,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "german.place(x=200,y=540,width=135,height=37)\n",
    "\n",
    "btn_french=Image.open(r\"image_resource\\button_french.png\")\n",
    "btn_french=btn_french.resize((132,34),Image.ANTIALIAS)\n",
    "btn_french=ImageTk.PhotoImage(btn_french)\n",
    "french=Button(root,image=btn_french,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "french.place(x=200,y=640,width=135,height=37)\n",
    "\n",
    "btn_bengali=Image.open(r\"image_resource\\button_bengali.png\")\n",
    "btn_bengali=btn_bengali.resize((132,34),Image.ANTIALIAS)\n",
    "btn_bengali=ImageTk.PhotoImage(btn_bengali)\n",
    "bengali=Button(root,image=btn_bengali,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "bengali.place(x=1210,y=340,width=135,height=37)\n",
    "\n",
    "btn_chinise=Image.open(r\"image_resource\\button_chinese.png\")\n",
    "btn_chinise=btn_chinise.resize((132,34),Image.ANTIALIAS)\n",
    "btn_chinise=ImageTk.PhotoImage(btn_chinise)\n",
    "chinise=Button(root,image=btn_chinise,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "chinise.place(x=1210,y=440,width=135,height=37)\n",
    "\n",
    "btn_tamil=Image.open(r\"image_resource\\button_tamil.png\")\n",
    "btn_tamil=btn_tamil.resize((132,34),Image.ANTIALIAS)\n",
    "btn_tamil=ImageTk.PhotoImage(btn_tamil)\n",
    "tamil=Button(root,image=btn_tamil,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "tamil.place(x=1210,y=540,width=135,height=37)\n",
    "\n",
    "btn_telugu=Image.open(r\"image_resource\\button_telugu.png\")\n",
    "btn_telugu=btn_telugu.resize((132,34),Image.ANTIALIAS)\n",
    "btn_telugu=ImageTk.PhotoImage(btn_telugu)\n",
    "telugu=Button(root,image=btn_telugu,bg='black',fg='red',cursor='hand2',border=0,borderwidth=0,activebackground='black')\n",
    "telugu.place(x=1210,y=640,width=135,height=37)\n",
    "\n",
    "\n",
    "root.mainloop()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "83cbe204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: remote origin already exists.\n"
     ]
    }
   ],
   "source": [
    "!git remote add origin https://github.com/ups1610/Text-summarizer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "84ee37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: src refspec main does not match any\n",
      "error: failed to push some refs to 'https://github.com/ups1610/Text-summarizer.git'\n"
     ]
    }
   ],
   "source": [
    "!git push --set-upstream origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "bbd8cc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 57, but you input_length is only 28. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" The power of the dragon scroll is . . Mine! It's nothing! I didn't get it the first time either . There is no secret ingredient. It's just you . I'm gonna pee! Don't! Don’t! You’re just\", \" Luffing! Shifu didn't teach you that! Nope . I figured it out. Skadoosh! I figured out. luffing. luffsing! I'm not sure what I'm doing . I'm going to do it. I'm\"]\n"
     ]
    }
   ],
   "source": [
    "from cgitb import text\n",
    "from traceback import print_tb\n",
    "from transformers import pipeline\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "myfile = open('link.txt', \"r\")\n",
    "you_link = myfile.readline()\n",
    "myfile.close()\n",
    "def youtube():\n",
    "    video_id = you_link.split(\"=\")[1]\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    full_transcript = \"\"\n",
    "    for x in transcript:\n",
    "        full_transcript += \" \" + x['text']\n",
    "\n",
    "    print(len(full_transcript))\n",
    "\n",
    "    summerizar = pipeline(\"summarization\")\n",
    "    itr = int(len(full_transcript)/400)\n",
    "    summary_text = []\n",
    "    for i in range(0, itr+1):\n",
    "        start = 0\n",
    "        start = i*400\n",
    "    \n",
    "        end = (i+1)*400\n",
    "        out = summerizar(full_transcript[start:end], max_length=57)\n",
    "        out = out[0]\n",
    "        out = out[\"summary_text\"]\n",
    "        summary_text.append(out)\n",
    "\n",
    "    print(summary_text)\n",
    "youtube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2606ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 200 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['संयुक्त राष्ट्र द्वारा मास्क पहनने को प्रोत्साहित']\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n",
    "article_en = \"U.N encourages wearing masks\"\n",
    "model_inputs = tokenizer(article_en, return_tensors=\"pt\")\n",
    "# translate from English to Hindi\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]\n",
    ")\n",
    "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5887a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'main' set up to track remote branch 'main' from 'https://github.com/ups1610/Youtube-Transcript.git'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/ups1610/Youtube-Transcript.git\n",
      " * [new branch]      main -> main\n"
     ]
    }
   ],
   "source": [
    "!git push -u  https://github.com/ups1610/Youtube-Transcript.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
